{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STIGWMx7jtrT",
        "outputId": "dbda8c1a-b862-40fb-a68d-c52ed40de530"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data\n",
        "!unzip \"/content/drive/MyDrive/data.zip\" -d \"/\""
      ],
      "metadata": {
        "id": "9nukeBNKj1kx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def countFile(link):\n",
        "    path = link\n",
        "    num_files = len([f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))])\n",
        "\n",
        "    print(\"Number of files in directory: \", num_files)"
      ],
      "metadata": {
        "id": "vRnBx7VEoUWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "countFile(\"data/happy\")\n",
        "countFile(\"data/sad\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CA3Y1jncojXx",
        "outputId": "620d2b9b-e20e-4d6d-f041-84faa1abdfd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of files in directory:  6906\n",
            "Number of files in directory:  4912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.models import Sequential\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "1opU0a8Tke1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(11)"
      ],
      "metadata": {
        "id": "qVy6wb6mvkWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_PATH = 'data/'\n",
        "EMOTIONS = [\"happy\",\"sad\"]\n",
        "IMAGE_SIZE = (96, 96)\n",
        "\n",
        "def image_generator(input_path, emotions, image_size):\n",
        "    for index, emotion in enumerate(emotions):\n",
        "        for filename in os.listdir(os.path.join(input_path, emotion)):\n",
        "            img = cv2.imread(os.path.join(input_path, emotion, filename))\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
        "            img = cv2.resize(img, image_size)\n",
        "            #img = img.astype('float32') / 255.0  # Normilize\n",
        "            yield img, index\n",
        "\n",
        "def load_images(input_path, emotions, image_size):\n",
        "    X, y = [], []\n",
        "    for img, label in image_generator(input_path, emotions, image_size):\n",
        "        X.append(img)\n",
        "        y.append(label)\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    return X, y\n"
      ],
      "metadata": {
        "id": "YxGI5cRylThH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = load_images(INPUT_PATH,EMOTIONS, IMAGE_SIZE)\n",
        "input_shape = X[0].shape"
      ],
      "metadata": {
        "id": "lYswCdF3msUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id_pos = np.where(y == 1)[0]\n",
        "id_neg = np.where(y == 0)[0]\n",
        "\n",
        "np.random.shuffle(id_pos)\n",
        "np.random.shuffle(id_neg)\n",
        "\n",
        "id_train_neg = id_neg[:int(len(id_neg) * 0.7)]\n",
        "id_train_pos = id_pos[:int(len(id_pos) * 0.7)]\n",
        "id_train = np.concatenate((id_train_neg, id_train_pos), axis = 0)\n",
        "\n",
        "id_val_neg = id_neg[int(len(id_neg) * 0.7):int(len(id_neg) * 0.9)]\n",
        "id_val_pos = id_pos[int(len(id_pos) * 0.7):int(len(id_pos) * 0.9)]\n",
        "id_val = np.concatenate((id_val_neg, id_val_pos), axis = 0)\n",
        "\n",
        "id_test_neg = id_neg[int(len(id_neg) * 0.9):]\n",
        "id_test_pos = id_pos[int(len(id_pos) * 0.9):]\n",
        "id_test = np.concatenate((id_test_neg, id_test_pos), axis = 0)"
      ],
      "metadata": {
        "id": "qiZgJLoKpqGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "#train\n",
        "x_train = X[id_train]\n",
        "y_train = y[id_train]\n",
        "#val\n",
        "x_val = X[id_val]\n",
        "y_val = y[id_val]\n",
        "#test\n",
        "x_test = X[id_test]\n",
        "y_test = y[id_test]\n",
        "\n",
        "y_train = y_train.reshape((-1, 1))\n",
        "y_val = y_val.reshape((-1, 1))\n",
        "y_test = y_test.reshape((-1, 1))\n",
        "y_train = to_categorical(y_train,dtype = 'int32')\n",
        "y_val = to_categorical(y_val,dtype = 'int32')\n",
        "y_test = to_categorical(y_test,dtype = 'int32')\n",
        "\n",
        "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
        "print(f\"x_val shape: {x_val.shape} - y_val shape: {y_val.shape}\")\n",
        "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9aW1GjlqOP9",
        "outputId": "9c402933-869e-447f-8e79-86180a03e8ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (8272, 96, 96, 3) - y_train shape: (8272, 2)\n",
            "x_val shape: (2363, 96, 96, 3) - y_val shape: (2363, 2)\n",
            "x_test shape: (1183, 96, 96, 3) - y_test shape: (1183, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data augmentation"
      ],
      "metadata": {
        "id": "mUeOhp4OsfyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 11"
      ],
      "metadata": {
        "id": "sJ_bTvOhuMyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Tạo một ImageDataGenerator object và cấu hình các phép biến đổi\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,  # xoay ảnh từ -20 đến +20 độ\n",
        "    width_shift_range=0.2,  # dịch chuyển theo chiều ngang từ -20% đến +20% của kích thước ảnh\n",
        "    height_shift_range=0.2,  # dịch chuyển theo chiều dọc từ -20% đến +20% của kích thước ảnh\n",
        "    horizontal_flip=True  # lật ảnh theo chiều ngang\n",
        ")\n",
        "\n",
        "# Fit data generator cho dữ liệu huấn luyện\n",
        "datagen.fit(x_train)"
      ],
      "metadata": {
        "id": "PUIpAIOHsNSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cau lenh de train model neu dung datagen\n",
        "model.fit(datagen.flow(x_train, y_train, batch_size=32), epochs=10, validation_data=(x_val, y_val))"
      ],
      "metadata": {
        "id": "IxsMqy161DdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augmentation_layer = Sequential([\n",
        "    layers.RandomCrop(92, 92, seed=SEED, input_shape=input_shape),\n",
        "    layers.Resizing(IMAGE_SIZE[0], IMAGE_SIZE[1]),\n",
        "    layers.RandomFlip(\"horizontal\", seed=SEED),\n",
        "    layers.RandomRotation(0.2, seed=SEED),\n",
        "], name=\"data_augmentation_layer\")"
      ],
      "metadata": {
        "id": "l2Cc3OWzsbP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Useful Code"
      ],
      "metadata": {
        "id": "YcpFL7It7juQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Run Example with early stoping and calculate f1 score\n",
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "def run_experiment(model, x_train, y_train,x_val, y_val, x_test, y_test):\n",
        "  \n",
        "    optimizer = tfa.optimizers.AdamW(\n",
        "        learning_rate=learning_rate, weight_decay=weight_decay\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=[\n",
        "            keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n",
        "            f1_m\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    checkpoint_filepath = \"/tmp/checkpoint\"\n",
        "\n",
        "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10)\n",
        "\n",
        "    history = model.fit(\n",
        "        x=x_train,\n",
        "        y=y_train,\n",
        "        batch_size=batch_size,\n",
        "        epochs=num_epochs,\n",
        "        validation_data=(x_val, y_val),\n",
        "        callbacks=[callback],\n",
        "    )\n",
        "\n",
        "    model.load_weights(checkpoint_filepath)\n",
        "    _, accuracy, f1_score = model.evaluate(x_test, y_test)\n",
        "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "    print(f\"Test F1 score: {round(f1_score * 100, 2)}%\")\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "X-FPZkOT7d-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Plot train and validation curves\n",
        "history = history.history\n",
        "loss = history['loss']\n",
        "v_loss = history['val_loss']\n",
        "\n",
        "acc = history['accuracy'] \n",
        "v_acc = history['val_accuracy']\n",
        "\n",
        "f1_score = history['f1_m']\n",
        "val_f1_score = history['val_f1_m']\n",
        "epochs = range(len(loss))\n",
        "\n",
        "fig = plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.yscale('log')\n",
        "plt.plot(epochs, loss, linestyle='--', linewidth=3, color='orange', alpha=0.7, label='Train Loss')\n",
        "plt.plot(epochs, v_loss, linestyle='-.', linewidth=2, color='lime', alpha=0.8, label='Valid Loss')\n",
        "# plt.ylim(0.3, 100)\n",
        "plt.xlabel('Epochs', fontsize=11)\n",
        "plt.ylabel('Loss', fontsize=12)\n",
        "plt.legend(fontsize=12)\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(epochs, acc, linestyle='--', linewidth=3, color='orange', alpha=0.7, label='Train Acc')\n",
        "plt.plot(epochs, v_acc, linestyle='-.', linewidth=2, color='lime', alpha=0.8, label='Valid Acc') \n",
        "plt.xlabel('Epochs', fontsize=11)\n",
        "plt.ylabel('Accuracy', fontsize=12)\n",
        "plt.legend(fontsize=12)\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.plot(epochs, f1_score, linestyle='--', linewidth=3, color='orange', alpha=0.7, label='Train F1 Score')\n",
        "plt.plot(epochs, val_f1_score, linestyle='-.', linewidth=2, color='lime', alpha=0.8, label='Valid F1 Score') \n",
        "plt.xlabel('Epochs', fontsize=11)\n",
        "plt.ylabel('F1 Score', fontsize=12)\n",
        "plt.legend(fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s68D3VQi1Cbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VZijmA3zuYd0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}